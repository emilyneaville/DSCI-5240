{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7108d478",
   "metadata": {},
   "source": [
    "### Assignment 3 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf76d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code appears in every demonstration Notebook.\n",
    "# By default, when you run each cell, only the last output of the codes will show.\n",
    "# This code makes all outputs of a cell show.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e823a5",
   "metadata": {},
   "source": [
    "In this assignment, we will build logistic regression models to detect accounting fraud using financial statement features. <br>\n",
    "The data was collected by Bao et al. (2020) based on the detected material accounting misstatements disclosed in the SEC’s Accounting and Auditing Enforcement Releases (AAERs). <br>\n",
    "The dataset covers all publicly listed U.S. firms over the period 1990– 2014. The variable name of the fraud label is \"misstate\" (1 denotes fraud, and 0 denotes non-fraud). <br>\n",
    "We will use both raw financial data from the financial statements and the financial ratios that are used to evaluate the financial performance of a company for detection.<br>\n",
    "\n",
    "You may find the description of variables in the Word document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71c155",
   "metadata": {},
   "source": [
    "1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6afeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c370c37",
   "metadata": {},
   "source": [
    "2. Read in the dataset and display basic information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b453ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc7194fe",
   "metadata": {},
   "source": [
    "3. Explore the variable 'misstate' with a graph. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157227f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b019f93f",
   "metadata": {},
   "source": [
    "4. Next we sum the number of fraud cases by year and make a line graph.<br>\n",
    "First we need to use .groupby() method to do the sum. We did not go over this in class. I explain here.\n",
    "Then you can use the result to create a line graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraud.groupby('fyear')['misstate'].sum().reset_index()\n",
    "\n",
    "# Groupby method group the data observations by the given variable 'fyear'\n",
    "# into groups.\n",
    "# Then the sum() will sum the variable 'misstate'\n",
    "# reset_index() is to transform the result into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f18e4",
   "metadata": {},
   "source": [
    "Save the output of the code above and make a line graph based on it. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32fbc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2481bda",
   "metadata": {},
   "source": [
    "5. The percentage of fraud cases is really small. To have better prediction power, we intend to oversample the fraud cases to 10% of the sample. Please run the code below. Pay attention to how I name the datasets. Change them to adapt to your cases. <br>\n",
    "You may notice that after oversampling, the number of fraud cases increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f1995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate into minority and majority\n",
    "minority_class = Fraud[Fraud['misstate'] == 1]\n",
    "majority_class = Fraud[Fraud['misstate'] == 0]\n",
    "\n",
    "# Count minority and majority samples\n",
    "minority_count = len(minority_class)\n",
    "majority_count = len(majority_class)\n",
    "print(\"Original class distribution:\", Fraud['misstate'].value_counts())\n",
    "\n",
    "###############################\n",
    "# Desired ratio = 10% / 90%   #\n",
    "###############################\n",
    "# For a 10/90 ratio, 1:9 (minority : majority)\n",
    "# If we have 'N' majority samples, we want M' = N/9 minority samples.\n",
    "\n",
    "RATIO = 9  # 1 minority : 9 majority\n",
    "majority_N = majority_count\n",
    "\n",
    "# Calculate how many minority samples we need to achieve 10/90 ratio\n",
    "minority_needed = int(np.ceil(majority_N / RATIO))\n",
    "\n",
    "# If we already have enough minority samples, no oversampling needed\n",
    "# Otherwise, sample (with replacement) from the minority to get the required count\n",
    "if minority_needed <= minority_count:\n",
    "    oversampled_minority = minority_class\n",
    "else:\n",
    "    # Randomly sample with replacement to reach minority_needed\n",
    "    oversampled_minority = minority_class.sample(n=minority_needed, replace=True, random_state=0)\n",
    "\n",
    "# Combine the new minority subset with the entire majority\n",
    "Fraud_oversampled = pd.concat([oversampled_minority, majority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "Fraud_oversampled = Fraud_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"New class distribution:\", Fraud_oversampled['misstate'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2fa11",
   "metadata": {},
   "source": [
    "6. Missing values. You may notice that some variables have missing values. <br>\n",
    "Ideally, we need to handle missing values carefully. We will explore that in the future if we have the chance.<br>\n",
    "For now, we just simply drop the observations with missing values. Use dropna() to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039457d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5a99249",
   "metadata": {},
   "source": [
    "7. Now let's fit logistic regression models. First, we only use the 14 financial ratio variables as the independent variables. You may find the definitions of them in the Word document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f94935",
   "metadata": {},
   "source": [
    "Prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257b901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a598b06b",
   "metadata": {},
   "source": [
    "8. Fit the model using statsmodels. Show the results. Which variables are not significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8dd572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
